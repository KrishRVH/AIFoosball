Steps,Policy/Entropy,Policy/Learning Rate,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Environment/Episode Length,Policy/Extrinsic Reward
10000,1.4189383,0.00029999999,-0.035962988,-3.642856569805493,1498.5,-3.593472480773926
20000,1.4189384,0.00029999999,-0.0280181,-3.2681213165737324,1498.5714285714287,-3.0372872182301114
30000,1.418963,0.00029999999,-0.059350118,-3.84913425421837,1498.4285714285713,-4.626636549830437
40000,1.418963,0.00029999999,-0.07149361,-3.558454704582497,1498.5,-5.245496162346432
50000,1.4186785,0.00029999999,-0.08415731,-4.019146301062262,1498.5714285714287,-4.8195547461509705
60000,1.4183238,0.00029999999,-0.10870822,-3.532923485688246,1498.4285714285713,-2.3081947614749274
70000,1.4181575,0.00029999999,-0.121338315,-3.9151085700820354,1498.5,-3.942589146750314
80000,1.418102,0.00029999999,-0.12752447,-3.3085089706187967,1498.5714285714287,-4.826026839869363
90000,1.417986,0.00029999999,-0.16188022,-3.6671816234967474,1498.4285714285713,-3.7634387612342834
100000,1.4179325,0.00029999999,-0.17751254,-3.733746257845875,1498.5,-4.322492011955807
110000,1.417753,0.00029999999,-0.18165505,-3.3752725483936956,1498.5714285714287,-3.3966880227838243
120000,1.4176184,0.00029999999,-0.1858351,-3.9016583220384615,1498.4285714285713,-3.4502585232257843
130000,1.4174466,0.00029999999,-0.18700822,-3.6951266834245566,1498.5,-4.618923127651215
140000,1.4172368,0.00029999999,-0.18555509,-3.3798673598025095,1498.5714285714287,-3.5420717171260288
150000,1.4171497,0.00029999999,-0.18110561,-3.7608151252685014,1498.4285714285713,-3.0778400798638663
